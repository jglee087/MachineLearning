# 2장. 시작하기 전에: 신경망의 수학적 구성 요소

딥러닝을 이해하려면 여러 가지 수학 개념과 친숙해져야 한다. 텐서, 텐서 연산, 미분, 경사 하강법 등이다. 텐서와 경사 하강법을 설명하기 위해 실제 신경망 예제로 이 장을 시작하겠다. 그리고 새로운 개념을 하나씩 소개한다.



### 2.1 신경망과의 첫 만남

케라스 파이썬 라이브러리를 사용하여 손글씨 숫자 분류를 학습하는 구체적인 신경망 예제를 살펴보자. 이 문제는 흑백 손글씨 숫자 이미지(28x28 픽셀)를 10개의 범주(0에서 9까지)로 분류하는 것이다. 머신 러닝 커뮤니티에서 고전으로 취급받는 데이터셋인 MNIST를 사용하자. 이 데이터셋은 6만 개의 훈련 이미지와 1만 개의 테스트 이미지로 구성되어 있다. MNIST 문제를 알고리즘이 제대로 작동하는지 확인하기 위해 딥러닝계의 'hello world'라고 생각해도 된다.



MNIST 데이터셋은 넘파이 배열 형태로 케라스에 이미 포함되어 있다.

- 케라스에서 MNIST 데이터셋 적재하기

```python

from keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

train_image와 train_labels가 모델이 학습해야 할 **훈련 세트**를 구성한다. 모델은 test_images와 test_labels로 구성된 **테스트 세트**에서 테스트될 것이다. 이미지는 넘파이 배열로 인코딩되어 있고 레이블은 0부터 9까지의 숫자 배열이다.

- 훈련 데이터의 정보

```python
>>> train_images.shape
(60000, 28, 28)
>>> len(train_labels)
60000
>>> train_labels
array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
```

- 테스트 데이터의 정보

```python
>>> test_images.shape
(10000, 28, 28)
>>> len(test_labels)
10000
>>> test_labels
array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)
```



작업 순서는 먼저 훈련 데이터를 네트워크에 주입한다. 그러면 네트워크는 이미지와 레이블을 연관시킬 수 있도록 학습된다. 마지막으로 test_images에 대한 예측을 네트워크에 요청한다. 그리고 이 예측이 test_labels와 맞는지 확인할 것이다.

- 신경망 만들기

```python
from keras import models
from keras import layers

network = models.Sequential()
network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))
network.add(layers.Dense(10, activation='softmax'))
```

신경망의 핵심 구성 요소는 일종의 데이터 처리 필터라고 생각할 수 있는 **층(layer)**이다. 어떤 데이터가 들어가면 더 유용한 형태로 출력된다. 조금 더 구체적으로 층은 주어진 문제에 더 의미 있는 **표현(representation)**을 입력된 데이터로부터 추출한다. 대부분의 딥러닝은 간단한 층을 연결하여 구성되어 있고, 점진적으로 데이터를 정제하는 형태를 띠고 있다. 딥러닝 모델은 데이터 정체 필터가 연속되어 있는 데이터 프로세싱을 위한 여과기와 같다.

이 예에서는 조밀하게 연결된 신경망 층인 Dense 층 2개가 연속되어 있다. 두 번째 층은 10개의 확률 점수가 들어 있는 배열을 반환하는 **소프트맥스(softmax)**층이다. 각 점수는 현재 숫자 이미지가 10개의 숫자 클래스 중 하나에 속할 확률이다.



신경망이 훈련 준비를 마치기 위해서 컴파일 단계에 포함될 세 가지가 더 필요하다.

1. **손실함수(Loss function)**: 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습될 수 있도록 도와주는 함수

2. **옵티마이저(Optimizer)**: 입력된 데이터와 손실함수를 기반으로 네트워크를 업데이트하는 메커니즘

3. **훈련과 테스트 과정을 모니터링할 지표**: 정확도와 다른 요소



- 컴파일 단계

```python
network.compile(optimizer='rmsprop', loss='categorical_crossentropy', 
                metrics=['accuracy'])
```



훈련을 시작하기 전에 데이터를 네트워크에 맞는 크기로 바꾸고 모든 값을 0과 1사이로 스케일을 조정한다. 훈련 이미지는 [0, 255] 사이의 값인 unit8 타입의 (60000, 28, 28) 크기를 가진 배열로 저장되어 있다. 이 데이터를 0과 1사이의 값을 가지는 float32 타입의 (60000, 28*28 ) 크기인 배열로 바꾼다.

- 이미지 데이터 준비하기

```python
train_images= train_images.reshape((60000,28*28))
train_images= train_images.astypee('float32')/255

test_images= test_images.reshape((10000,28*28))
test_images= test_images.astypee('float32')/255
```



- 레이블 준비하기

```python
from keras.utils import to_categorical

train_labels= to_categorical(train_labels)
test_labes= to_categorical(test_labels)
```



- fit 메서드를 호출하여 훈련 데이터에 모델을 학습

```python
network.fit(train_images, train_labels, epochs=5, batch_size=128)
```

훈련하는 동안 2개의 정보가 출력된다. 훈련데이터에 대한 네트워크의 손실과 정확도이다.



- 테스트 세트에서 모델이 작동하는지 확인

```python
>>> test_loss, test_acc = network.evaluate(test_images, test_labels)
>>> print('test_acc:', test_acc)
test_acc: ####
```



계산을 하면 테스트 세트의 정확도는 훈련 세트 정확도보다는 약간 낮다. 훈련 정확도와 테스트 정확도 사이의 차이는 **과대적합(overfitting)**때문이다. 이는 머신 러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경향을 말한다.



### 2.2 신경망을 위한 데이터 표현

**텐서(tensor)**라 부르는 다차원 넘파이 배열에 데이터를 저장하는 것부터 시작했다. 최근의 모든 머신 러닝 시스템은 일반적으로 텐서를 기본 데이터 구조로 사용한다. 텐서는 머신 러닝의 기본 구성 요소이다. 그럼 텐서는 무엇일까?

핵심적으로 텐서는 데이터를 위한 컨테이너이다. 거의 항상 수치형 데이터를 다루므로 숫자를 위한 컨테이너이다. 2D 텐서인 행렬에 대해 이미 알고 있을 것이다. 텐서는 임의의 차원 개수를 가지는 행렬의 일반화된 모습이다(텐서에서는 **차원(dimension)**을 종종 **축(axis)**이라고 한다).



#### 2.2.1 스칼라(0D 텐서)

하나의 숫자만 담고 있는 텐서를 **스칼라(scalar)**(또는 0차원 텐서, 0D 텐서)라고 부른다. 넘파이에서는 float32나 float64 타입의 숫자가 스칼라 텐서이다. **ndim** 속성을 사용하면 넘파이 **배열의 축 개수**를 확인할 수 있다. 스칼라 텐서의 축 개수는 0이다. 텐서의 축 개수를 **랭크(rank)**라고 한다. 

```python
import numpy as np
x= np.array(12)
>>> x.ndim
0
```



#### 2.2.2 벡터(1D 텐서)

숫자의 배열을 **벡터(vector)** 또는 1D 텐서라고 한다. 1D 텐서는 딱 하나의 축을 가진다. 

```python
>>> x=np.array([1,2,3,4,5])
>>> x
array([1,2,3,4,5])
>>> x.ndim
1
```

이 벡터는 5개의 원소를 가지고 있으므로 5차원 벡터라고 부른다. <u>5D 벡터</u>와 <u>5D 텐서</u>를 혼동하면 안된다. 5D 벡터는 하나의 축을 따라 5개의 차원을 가진 것이고 5D 텐서는 5개의 축을 가진 것이다. **차원수**는 특정 축을 따라 놓인 원소의 개수이거나 텐서의 축 개수를 의미하므로 혼동하기 쉽다. 후자의 경우 랭크 5인 텐서라고 말하는 것이 기술적으로 더 정확하다.



#### 2.2.3 행렬(2D 텐서)

벡터의 배열이 **행렬(matrix)** 또는 2D 텐서이다. 행렬에는 2개의 축이 있다(보통 **행(row)**과 **열(column**)이라고 한다). 행렬은 숫자가 채워진 사각 격자라고 생각할 수 있다. 넘파이에서 행렬을 나타내면 다음과 같다.

```python
>>> x=np.array([ [1,2,3,4],
                 [5,6,7,8],
                 [9,0,1,2] ])
>>> x.ndim
2
```

첫 번째 축에 놓여 있는 원소를 **행**이라 하고, 두 번째 축에 놓여 있는 원소를 **열**이라고 한다. 앞의 예에서는 x의 첫 번째 행은 [1,2,3,4]이고, 첫 번째 열은 [1,5,9]이다.



#### 2.2.4 3D 텐서와 고차원 텐서

이런 행렬들은 하나의 새로운 배열로 합치면 숫자가 채워진 직융면체 형태로 해석할 수 있는 3D 텐서가 만들어진다. 넘파이에서 3D 텐서를 나타내면 다음과 같다.

```python
>>> x = np.array([ [[1,2,3,4,5],
                    [6,7,8,9,0],
                    [1,2,3,4,5]], 
                   [[11,12,13,14,15],
                    [16,17,18,19,20],
                    [21,22,23,24,25]],
                   [[51,52,53,54,55],
                    [56,57,58,59,60],
                    [61,62,63,64,65]]])
>>> x.ndim
3
```

3D 텐서들을 하나의 배열로 합치면 4D 텐서를 만들 수 있다. 딥러닝에서는 보통 0D에서 4D까지의 텐서를 다룬다. 동영상 데이터를 다룰 경우에는 5D 텐서를 사용한다.



#### 2.2.5 핵심 속성

텐서는 **3개의 핵심 속성**으로 정의된다.

1. **축의 개수(랭크)**: 3D 텐서에는 3개의 축이 있고, 행렬에는 2개의 축이 있다. 넘파이 라이브러리에서는 **ndim**속성에 저장되어 있다.
2. **크기**: 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플이다. 예를 들어 앞에 나온 행렬의 크기는 (3, 5)이고 3D 텐서의 크기는 (3, 3, 5)이다. 벡터의 크기는 (5, )처럼 1개의 원소로 이루어진 튜플이다.
3. **데이터 타입**: 텐서에 포함된 데이터의 타입이다. 예를 들어 텐서의 타입은 float32, uint8, float64 등이 될 수 있다. 드물게 char 타입을 사용한다. 텐서는 사전에 할당되어 연속된 메모리에 저장되어야 하므로 넘파이 배열은 가변 길이의 문자열을 지원하지 않는다.



MNIST 데이터셋을 다시 살펴보자.

1. 축의 개수는 ndim 속성으로 축의 개수를 확인한다.

   print(train_images.ndim)

2. 배열의 크기는 shape으로 확인한다.
   print(train_images.shape)

3. 데이터 타입은 dtype으로 확인한다.

   print(train_images.dtype)

이 배열은 8비트 정수형 3D 텐서이다. 정확하게는 28x28 크기의 정수 행렬 6만개가 있는 배열이다. 각 행렬은 하나의 흑백 이미지고, 행렬의 각 원소는 0에서 255 사이의 값을 가진다.



#### 2.2.6 넘파이로 텐서 조작하기



